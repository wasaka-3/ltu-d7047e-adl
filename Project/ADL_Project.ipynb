{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpEfjxhtaBha"
   },
   "source": [
    "# Final Project - Advanced Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QasDpEPDZlc_"
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    # Check if file already exists locally\n",
    "    if os.path.exists(local_filename):\n",
    "        print(f\"{local_filename} already exists locally.\")\n",
    "        return\n",
    "\n",
    "    # Download the file\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        response.raise_for_status()  # Ensure we raise an error for bad responses\n",
    "        with open(local_filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "    print(f\"Downloaded {local_filename} from {url}.\")\n",
    "\n",
    "\n",
    "def unzip_file(zip_filepath, extract_to):\n",
    "    # Check if the extracted directory already exists\n",
    "    if os.path.isdir(extract_to):\n",
    "        print(f\"Directory {extract_to} already exists. Skipping extraction.\")\n",
    "        return\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Extracted {zip_filepath} to {extract_to}.\")\n",
    "\n",
    "\n",
    "\n",
    "# this url is available for only a limited time.\n",
    "dataset_url = \"http://t12s-418866851410-ltu-adl.s3-website.eu-central-1.amazonaws.com/chest_xray.zip\"\n",
    "local_zip_filename = \"/tmp/chest_xray.zip\"\n",
    "extract_to = \"/tmp/ltu-chest-xray\"\n",
    "\n",
    "# Download the file if not already downloaded\n",
    "download_file(dataset_url, local_zip_filename)\n",
    "\n",
    "# Unzip the file if not already unzipped\n",
    "unzip_file(local_zip_filename, extract_to)\n",
    "\n",
    "\n",
    "# Define directories\n",
    "train_dir = '/tmp/ltu-chest-xray/chest_xray/train/'\n",
    "val_dir = '/tmp/ltu-chest-xray/chest_xray/val/'\n",
    "test_dir = '/tmp/ltu-chest-xray/chest_xray/test/'\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.samples // val_generator.batch_size),\n",
    "    epochs=25\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=max(1, test_generator.samples // test_generator.batch_size))\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "# Predict the labels for test set\n",
    "Y_pred = model.predict(test_generator, steps=(test_generator.samples // test_generator.batch_size) + 1)\n",
    "y_pred = np.round(Y_pred).astype(int)\n",
    "\n",
    "# Ensuring y_pred matches the number of test samples\n",
    "y_pred = y_pred[:test_generator.samples]\n",
    "\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate F-score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}, Precision: {precision}, Recall: {recall}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualization with TensorBoard\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Visualization with Weights & Biases\n",
    "!pip install wandb\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "wandb.init(project=\"pneumonia-detection\")\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=max(1, val_generator.samples // val_generator.batch_size),\n",
    "    epochs=25,\n",
    "    callbacks=[WandbCallback()]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
