{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:18:48.994876500Z",
          "start_time": "2024-04-21T08:18:40.547079800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:03.465741Z",
          "iopub.status.busy": "2024-04-21T13:27:03.465370Z",
          "iopub.status.idle": "2024-04-21T13:27:09.436298Z",
          "shell.execute_reply": "2024-04-21T13:27:09.435361Z",
          "shell.execute_reply.started": "2024-04-21T13:27:03.465706Z"
        },
        "id": "initial_id",
        "outputId": "6a61949c-7cd0-439e-91bd-f0aee8c56ef3",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import math\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parallel import DataParallel"
      ],
      "id": "initial_id"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:18:49.048219300Z",
          "start_time": "2024-04-21T08:18:48.992785200Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:09.439438Z",
          "iopub.status.busy": "2024-04-21T13:27:09.438631Z",
          "iopub.status.idle": "2024-04-21T13:27:09.496270Z",
          "shell.execute_reply": "2024-04-21T13:27:09.495274Z",
          "shell.execute_reply.started": "2024-04-21T13:27:09.439399Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upArkxQIJ0wY",
        "outputId": "c1ebfe37-947d-4cc8-fd0e-101db0cb5225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Training on GPU.\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Training on GPU.\")\n",
        "    device = torch.device(\"cuda\")  # Select GPU device\n",
        "else:\n",
        "    print(\"CUDA is not available. Training on CPU.\")\n",
        "    device = torch.device(\"cpu\")   # Fall back to CPU"
      ],
      "id": "upArkxQIJ0wY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:20:48.731265800Z",
          "start_time": "2024-04-21T08:20:36.959975300Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:09.498281Z",
          "iopub.status.busy": "2024-04-21T13:27:09.497937Z",
          "iopub.status.idle": "2024-04-21T13:27:11.460525Z",
          "shell.execute_reply": "2024-04-21T13:27:11.459796Z",
          "shell.execute_reply.started": "2024-04-21T13:27:09.498247Z"
        },
        "id": "b3f05bb934461fa1",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2feb6e6-edc8-463b-f23f-7b7c96fcba8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "def preprocess_pandas(data, columns):\n",
        "    df_ = pd.DataFrame(columns=columns)\n",
        "    data['Sentence'] = data['Sentence'].str.lower()\n",
        "    data['Sentence'] = data['Sentence'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n",
        "    data['Sentence'] = data['Sentence'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n",
        "    data['Sentence'] = data['Sentence'].str.replace('[^\\w\\s]','')                                                       # remove special characters\n",
        "    data['Sentence'] = data['Sentence'].replace('\\d', '', regex=True)                                                   # remove numbers\n",
        "\n",
        "    df_list = []\n",
        "    for index, row in data.iterrows():\n",
        "        word_tokens = word_tokenize(row['Sentence'])\n",
        "        filtered_sent = [w for w in word_tokens if not w in stopwords.words('english')]\n",
        "        df_list.append({\n",
        "            \"index\": row['index'],\n",
        "            \"Class\": row['Class'],\n",
        "            \"Sentence\": \" \".join(filtered_sent[0:])\n",
        "        })\n",
        "    df_ = pd.DataFrame(df_list)\n",
        "    return df_\n",
        "\n",
        "# get data, pre-process and split\n",
        "try:\n",
        "    data = pd.read_csv(\"/content/dataset/amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
        "except:\n",
        "    data = pd.read_csv(\"amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
        "\n",
        "data.columns = ['Sentence', 'Class']\n",
        "data['index'] = data.index                                          # add new column index\n",
        "columns = ['index', 'Class', 'Sentence']\n",
        "data = preprocess_pandas(data, columns)                             # pre-process\n",
        "training_data, val_data, training_labels, val_labels = train_test_split( # split the data into training, validation, and test splits\n",
        "    data['Sentence'].values.astype('U'),\n",
        "    data['Class'].values.astype('int32'),\n",
        "    test_size=0.30,\n",
        "    random_state=0,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_data, test_data, validation_labels, test_labels = train_test_split(val_data, val_labels,test_size=0.50, random_state=0, shuffle=True)\n",
        "\n",
        "\n",
        "# vectorize data using TFIDF and transform for PyTorch for scalability\n",
        "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=50000, max_df=0.5, use_idf=True, norm='l2')\n",
        "training_data = word_vectorizer.fit_transform(training_data)        # transform texts to sparse matrix\n",
        "training_data = training_data.todense()                             # convert to dense matrix for Pytorch\n",
        "vocab_size = len(word_vectorizer.vocabulary_)\n",
        "validation_data = word_vectorizer.transform(validation_data)\n",
        "validation_data = validation_data.todense()\n",
        "test_data = word_vectorizer.transform(test_data)\n",
        "test_data = test_data.todense()\n",
        "train_x_tensor = torch.from_numpy(np.array(training_data)).type(torch.FloatTensor)\n",
        "train_y_tensor = torch.from_numpy(np.array(training_labels)).long()\n",
        "validation_x_tensor = torch.from_numpy(np.array(validation_data)).type(torch.FloatTensor)\n",
        "validation_y_tensor = torch.from_numpy(np.array(validation_labels)).long()\n",
        "test_x_tensor = torch.from_numpy(np.array(test_data)).type(torch.FloatTensor)\n",
        "test_y_tensor = torch.from_numpy(np.array(test_labels)).long()\n",
        "\n",
        "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
        "validation_dataset = TensorDataset(validation_x_tensor, validation_y_tensor)\n",
        "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoader for training and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size,num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,num_workers=4)"
      ],
      "id": "b3f05bb934461fa1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:18:56.944912100Z",
          "start_time": "2024-04-21T08:18:56.880129100Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:11.462298Z",
          "iopub.status.busy": "2024-04-21T13:27:11.462012Z",
          "iopub.status.idle": "2024-04-21T13:27:11.476427Z",
          "shell.execute_reply": "2024-04-21T13:27:11.475658Z",
          "shell.execute_reply.started": "2024-04-21T13:27:11.462274Z"
        },
        "id": "a8574c184e10e8da",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Chatbot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,num_layers,output_size,dropout=0.2):\n",
        "        super(Chatbot,self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=dropout,batch_first=True)\n",
        "        self.fc = nn.Linear(in_features=hidden_size,out_features=output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        x = x.unsqueeze(1)\n",
        "        out, _ = self.lstm(x, (h0, c0))  # Forward pass through LSTM\n",
        "        out = self.fc(out[:, -1, :])  # Take the last output and pass it through a linear layer\n",
        "        out = self.sigmoid(out)  # Apply sigmoid activation\n",
        "        return out\n",
        "\n",
        "class ChatbotSimple(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ChatbotSimple, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "        embedded = self.embedding(x)\n",
        "        embedded_avg = torch.mean(embedded, dim=1)  # Average pooling over the sequence dimension\n",
        "        output = self.fc(embedded_avg)\n",
        "        return output\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.2, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(ntoken, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout),\n",
        "            nlayers\n",
        "        )\n",
        "        self.linear = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        src = src.long()\n",
        "        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
        "        src = src.transpose(0, 1)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = output.transpose(0, 1)\n",
        "        output = self.linear(output)\n",
        "        return output"
      ],
      "id": "a8574c184e10e8da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T07:08:06.462655700Z",
          "start_time": "2024-04-18T07:08:06.447795800Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:11.480162Z",
          "iopub.status.busy": "2024-04-21T13:27:11.479896Z",
          "iopub.status.idle": "2024-04-21T13:27:11.493391Z",
          "shell.execute_reply": "2024-04-21T13:27:11.492642Z",
          "shell.execute_reply.started": "2024-04-21T13:27:11.480140Z"
        },
        "id": "7ec8a4d9b210440a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "def train_model(model,criterion,optimizer,num_epochs,train_loader,validation_loader,device, model_name,num_classes: int = 2):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_sd = None\n",
        "    model.to(device)\n",
        "    # Training loop\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()  # Set the model to training mode\n",
        "\n",
        "        for inputs,labels in train_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          labels_one_hot = F.one_hot(labels, num_classes=num_classes).long()\n",
        "          if 'lstm' in model_name or 'simple_bot'in model_name:\n",
        "              labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
        "          optimizer.zero_grad()  # Zero the gradients\n",
        "          outputs = model(inputs)  # Forward pass\n",
        "          loss = criterion(outputs,labels_one_hot)\n",
        "          loss.backward()  # Backward pass\n",
        "          optimizer.step()  # Update weights\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in validation_loader:\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "              labels_one_hot = F.one_hot(labels, num_classes=num_classes).long()\n",
        "              if 'lstm' in model_name or 'simple_bot'in model_name:\n",
        "                  labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
        "              outputs = model(inputs)  # Forward pass\n",
        "              val_loss = criterion(outputs,labels_one_hot)\n",
        "\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
        "\n",
        "        # Save the model with the best validation loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_sd = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # Empty CUDA cache to release GPU memory\n",
        "        #torch.cuda.empty_cache()\n",
        "\n",
        "    model.load_state_dict(best_model_sd)\n",
        "\n",
        "    # Plot training and validation losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    torch.save(model.state_dict(), model_name)"
      ],
      "id": "7ec8a4d9b210440a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:20:48.855429900Z",
          "start_time": "2024-04-21T08:20:48.763139200Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:11.495245Z",
          "iopub.status.busy": "2024-04-21T13:27:11.494552Z",
          "iopub.status.idle": "2024-04-21T13:27:11.508200Z",
          "shell.execute_reply": "2024-04-21T13:27:11.507324Z",
          "shell.execute_reply.started": "2024-04-21T13:27:11.495215Z"
        },
        "id": "4e707d578079e877",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "def test_model(model, test_loader, device, model_name,num_classes: int = 2):\n",
        "    classes = ['positive', 'negative']\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.load_state_dict(torch.load(model_name))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        _, labels_indices = labels_one_hot.max(dim=1)\n",
        "        if predicted.size() == labels_indices.size():\n",
        "            correct += (predicted == labels_indices).sum().item()\n",
        "        else:\n",
        "            correct += (predicted == labels_indices.unsqueeze(1)).sum().item()\n",
        "\n",
        "\n",
        "    y_true_indices = convert_to_indices(y_true)\n",
        "    y_pred_indices = convert_to_indices(y_pred)\n",
        "\n",
        "    print(f'Test accuracy of the network: {100 * correct // total} %')\n",
        "    cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def convert_to_indices(label_list):\n",
        "    indices = []\n",
        "    for label in label_list:\n",
        "        if isinstance(label, np.ndarray):\n",
        "            index = np.argmax(label)\n",
        "        elif isinstance(label, torch.Tensor):\n",
        "            index = torch.argmax(label).item()\n",
        "        else:\n",
        "            index = label  # Assume it's already an index\n",
        "        indices.append(index)\n",
        "    return indices"
      ],
      "id": "4e707d578079e877"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:19:05.774845900Z",
          "start_time": "2024-04-21T08:19:05.718810600Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:11.509666Z",
          "iopub.status.busy": "2024-04-21T13:27:11.509309Z",
          "iopub.status.idle": "2024-04-21T13:27:11.576439Z",
          "shell.execute_reply": "2024-04-21T13:27:11.575786Z",
          "shell.execute_reply.started": "2024-04-21T13:27:11.509634Z"
        },
        "id": "d39d1fca1375bda6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "input_size = vocab_size  # Size of vocabulary\n",
        "hidden_size = 256  # Size of hidden layer\n",
        "output_size = 2  # Size of vocabulary (for response)\n",
        "num_layers = 2\n",
        "model_name_lstm = 'lstm_bot.pth'\n",
        "model_lstm = Chatbot(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)"
      ],
      "id": "d39d1fca1375bda6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T13:27:11.577558Z",
          "iopub.status.busy": "2024-04-21T13:27:11.577291Z",
          "iopub.status.idle": "2024-04-21T13:29:41.952339Z",
          "shell.execute_reply": "2024-04-21T13:29:41.951091Z",
          "shell.execute_reply.started": "2024-04-21T13:27:11.577531Z"
        },
        "trusted": true,
        "id": "Q8xpybVWJ0wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3816efbe-ce10-45b2-c709-e2bb34e12d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/300, Training Loss: 0.6810, Validation Loss: 0.6892\n",
            "Epoch 20/300, Training Loss: 0.2520, Validation Loss: 0.4820\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model_lstm = DataParallel(model_lstm)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model_lstm.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(model=model_lstm, criterion=criterion, optimizer=optimizer, train_loader=train_loader,\n",
        "                                 validation_loader=validation_loader, num_epochs=epochs, device=device,\n",
        "                                 model_name=model_name_lstm)"
      ],
      "id": "Q8xpybVWJ0wZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:20:56.393055200Z",
          "start_time": "2024-04-21T08:20:56.297008600Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:29:41.954600Z",
          "iopub.status.busy": "2024-04-21T13:29:41.954017Z",
          "iopub.status.idle": "2024-04-21T13:29:42.487185Z",
          "shell.execute_reply": "2024-04-21T13:29:42.486184Z",
          "shell.execute_reply.started": "2024-04-21T13:29:41.954571Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "UQoJSDgzJ0wZ"
      },
      "outputs": [],
      "source": [
        "test_model(model=model_lstm,test_loader=test_loader,device=device,model_name=model_name_lstm)"
      ],
      "id": "UQoJSDgzJ0wZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-16T06:59:24.856743500Z",
          "start_time": "2024-04-16T06:47:59.915709700Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:29:42.488911Z",
          "iopub.status.busy": "2024-04-21T13:29:42.488642Z",
          "iopub.status.idle": "2024-04-21T13:29:42.504387Z",
          "shell.execute_reply": "2024-04-21T13:29:42.503734Z",
          "shell.execute_reply.started": "2024-04-21T13:29:42.488885Z"
        },
        "id": "609d1fa839e0a869",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "input_size = vocab_size  # Size of vocabulary\n",
        "hidden_size = 256  # Size of hidden layer\n",
        "output_size = 2  # Size of vocabulary (for response)\n",
        "num_layers = 2\n",
        "model_name_simple_bot = 'simple_bot.pth'\n",
        "model_simple_bot = ChatbotSimple(input_size=input_size, hidden_size=hidden_size, output_size=output_size)"
      ],
      "id": "609d1fa839e0a869"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T13:29:42.505555Z",
          "iopub.status.busy": "2024-04-21T13:29:42.505289Z",
          "iopub.status.idle": "2024-04-21T13:31:50.944198Z",
          "shell.execute_reply": "2024-04-21T13:31:50.943042Z",
          "shell.execute_reply.started": "2024-04-21T13:29:42.505529Z"
        },
        "trusted": true,
        "id": "lpRvKKbCJ0wa"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model_simple_bot = DataParallel(model_simple_bot)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_simple_bot.parameters(),lr=0.0001)\n",
        "\n",
        "trained_model_emb = train_model(model=model_simple_bot,criterion=criterion,optimizer=optimizer,train_loader=train_loader,validation_loader=validation_loader,num_epochs=epochs,device=device,model_name=model_name_simple_bot)\n"
      ],
      "id": "lpRvKKbCJ0wa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:21:00.808407200Z",
          "start_time": "2024-04-21T08:21:00.656458Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:31:50.946393Z",
          "iopub.status.busy": "2024-04-21T13:31:50.945967Z",
          "iopub.status.idle": "2024-04-21T13:31:51.464755Z",
          "shell.execute_reply": "2024-04-21T13:31:51.463752Z",
          "shell.execute_reply.started": "2024-04-21T13:31:50.946353Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "QLEO2Is0J0wa"
      },
      "outputs": [],
      "source": [
        "test_model(model=model_simple_bot,test_loader=test_loader,device=device,model_name=model_name_simple_bot)"
      ],
      "id": "QLEO2Is0J0wa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:01:18.567101Z",
          "start_time": "2024-04-18T07:08:06.496450900Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:31:51.466292Z",
          "iopub.status.busy": "2024-04-21T13:31:51.465995Z",
          "iopub.status.idle": "2024-04-21T13:31:51.483907Z",
          "shell.execute_reply": "2024-04-21T13:31:51.482894Z",
          "shell.execute_reply.started": "2024-04-21T13:31:51.466264Z"
        },
        "id": "79ad964ef9a63162",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "ntokens = vocab_size  # size of vocabulary\n",
        "emsize = 2  # embedding dimension\n",
        "d_hid = 1  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
        "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
        "nhead = 1  # number of heads in ``nn.MultiheadAttention``\n",
        "dropout = 0.5  # dropout probability\n",
        "model_name_transformer = 'transformer_bot.pth'\n",
        "model_transformer = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ],
      "id": "79ad964ef9a63162"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T13:31:51.487956Z",
          "iopub.status.busy": "2024-04-21T13:31:51.487686Z",
          "iopub.status.idle": "2024-04-21T13:44:48.744125Z",
          "shell.execute_reply": "2024-04-21T13:44:48.743098Z",
          "shell.execute_reply.started": "2024-04-21T13:31:51.487933Z"
        },
        "trusted": true,
        "id": "zmZI2XuoJ0wa"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model_transformer = DataParallel(model_transformer)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_transformer.parameters(), lr=0.001,weight_decay=0.001)\n",
        "\n",
        "train_model(model=model_transformer,criterion=criterion,optimizer=optimizer,train_loader=train_loader,validation_loader=validation_loader,num_epochs=epochs,device=device,model_name=model_name_transformer)"
      ],
      "id": "zmZI2XuoJ0wa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:27:04.922185Z",
          "start_time": "2024-04-21T08:27:04.864520400Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T13:44:48.746691Z",
          "iopub.status.busy": "2024-04-21T13:44:48.745828Z",
          "iopub.status.idle": "2024-04-21T13:44:49.415849Z",
          "shell.execute_reply": "2024-04-21T13:44:49.414844Z",
          "shell.execute_reply.started": "2024-04-21T13:44:48.746649Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "GHBT5iYcJ0wa"
      },
      "outputs": [],
      "source": [
        "test_model(model=model_transformer,test_loader=test_loader,device=device,model_name=model_name_transformer)"
      ],
      "id": "GHBT5iYcJ0wa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:27:07.357647100Z",
          "start_time": "2024-04-21T08:27:06.363850600Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T14:02:01.652912Z",
          "iopub.status.busy": "2024-04-21T14:02:01.652572Z",
          "iopub.status.idle": "2024-04-21T14:02:01.661926Z",
          "shell.execute_reply": "2024-04-21T14:02:01.660864Z",
          "shell.execute_reply.started": "2024-04-21T14:02:01.652888Z"
        },
        "id": "f91f26722f55d1cb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def analyze_sentiment(text, model_lstm, model_transformer, model_name_lstm, model_name_transformer):\n",
        "    text = word_vectorizer.transform([text])\n",
        "    text = text.todense()  # convert to dense matrix for Pytorch\n",
        "    text_tensor_ltsm = torch.from_numpy(np.array(text)).type(torch.FloatTensor)\n",
        "    text_tensor_transformer = torch.from_numpy(np.array(text)).type(torch.LongTensor)\n",
        "\n",
        "    model_lstm.load_state_dict(torch.load(model_name_lstm))\n",
        "    model_lstm.to(device)\n",
        "    model_lstm.eval()\n",
        "\n",
        "    model_transformer.load_state_dict(torch.load(model_name_transformer))\n",
        "    model_transformer.to(device)\n",
        "    model_transformer.eval()\n",
        "\n",
        "    sentiment2, sentiment1 = None,None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model_lstm(text_tensor_ltsm)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        sentiment2 = \"positive\" if predicted.item() == 1 else \"negative\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_tr = model_transformer(text_tensor_transformer)\n",
        "        output_tr = output_tr.view(-1)\n",
        "        _, predicted_tr = torch.max(output_tr, 0)\n",
        "        sentiment1 = \"positive\" if predicted_tr.item() == 1 else \"negative\"\n",
        "\n",
        "\n",
        "\n",
        "    return f\"LTSM - {sentiment2}, Transformer - {sentiment1}\""
      ],
      "id": "f91f26722f55d1cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-21T08:18:34.971589Z",
          "start_time": "2024-04-21T08:18:26.492001400Z"
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T14:13:53.549081Z",
          "iopub.status.busy": "2024-04-21T14:13:53.548706Z",
          "iopub.status.idle": "2024-04-21T14:15:27.167217Z",
          "shell.execute_reply": "2024-04-21T14:15:27.166243Z",
          "shell.execute_reply.started": "2024-04-21T14:13:53.549055Z"
        },
        "id": "e44bf7efc69f81c2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"Welcome to the Sentiment Analysis Chatbot!\")\n",
        "while True:\n",
        "    user_input = input(\"Please enter your review: \")\n",
        "    if user_input.lower() == \"exit\" or user_input == \"\":\n",
        "        print(\"Exit command. Exiting the chatbot.\")\n",
        "        break\n",
        "    else:\n",
        "        print(f\"User feedback: {user_input}\")\n",
        "        sentiment = analyze_sentiment(user_input, model_lstm, model_transformer, model_name_lstm, model_name_transformer)\n",
        "        print(f\"The sentiment of your review is {sentiment}.\\n\")"
      ],
      "id": "e44bf7efc69f81c2"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 8276080,
          "datasetId": 4823480,
          "isSourceIdPinned": false,
          "sourceId": 8154647,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}